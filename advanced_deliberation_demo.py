#!/usr/bin/env python3
"""
ğŸ§  Advanced Collaborative AI Deliberation Demo
Showcasing local model deliberation with cloud summarizer system
"""

import time
import sys
import os

# Add the project directory to the path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from iblu_assistant import KaliGPTMCPAssistant

def demo_advanced_deliberation():
    """Demonstrate advanced collaborative deliberation system"""
    print("ğŸ§  Advanced Collaborative AI Deliberation Demo")
    print("=" * 50)
    
    # Initialize the assistant
    try:
        assistant = KaliGPTMCPAssistant()
        print("âœ… Assistant initialized successfully")
    except Exception as e:
        print(f"âŒ Failed to initialize assistant: {e}")
        return
    
    # Check available models
    print("\nğŸ” Checking available models...")
    
    # Check local models
    local_models = []
    try:
        import requests
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            models_data = response.json()
            for model in models_data.get('models', []):
                model_name = model.get('name', '').lower()
                if any(keyword in model_name for keyword in ['dolphin', 'llama', 'mistral', 'qwen', 'deepseek']):
                    local_models.append(model.get('name'))
        print(f"ğŸ¦™ Found {len(local_models)} local models: {', '.join(local_models)}")
    except Exception as e:
        print(f"âŒ Error checking local models: {e}")
    
    # Check cloud providers
    cloud_providers = []
    for provider in ['openai', 'gemini', 'mistral']:
        keys = assistant.get_provider_keys(provider.upper() if provider != 'mistral' else 'MISTRAL')
        if keys:
            cloud_providers.append(provider)
    print(f"â˜ï¸ Found {len(cloud_providers)} cloud providers: {', '.join(cloud_providers)}")
    
    # Test deliberation if we have enough models
    if len(local_models) >= 3 and len(cloud_providers) >= 1:
        print("\nğŸš€ Starting advanced deliberation test...")
        test_questions = [
            "How to perform a network security assessment",
            "What are the best practices for password security",
            "How to set up a secure web server"
        ]
        
        for i, question in enumerate(test_questions, 1):
            print(f"\n--- Test Question {i}: {question} ---")
            try:
                response = assistant.advanced_collaborative_deliberation(
                    question, 
                    local_models[:3], 
                    [(cloud_providers[0].upper(), "test_key")]
                )
                print(f"âœ… Deliberation {i} completed successfully")
                print(f"Response length: {len(response)} characters")
            except Exception as e:
                print(f"âŒ Deliberation {i} failed: {e}")
            
            if i < len(test_questions):
                print("â³ Waiting 3 seconds before next test...")
                time.sleep(3)
    
    else:
        print(f"\nâŒ Insufficient models for deliberation:")
        print(f"   Local models needed: 3+, available: {len(local_models)}")
        print(f"   Cloud providers needed: 1+, available: {len(cloud_providers)}")
        
        if len(local_models) > 0:
            print(f"\nğŸ¦™ Available local models:")
            for model in local_models:
                print(f"   â€¢ {model}")
        
        if len(cloud_providers) > 0:
            print(f"\nâ˜ï¸ Available cloud providers:")
            for provider in cloud_providers:
                print(f"   â€¢ {provider}")
        
        print(f"\nğŸ’¡ To enable advanced deliberation:")
        print(f"   1. Install at least 3 local models: /install_llama, /install_dolphin, /install_mistral")
        print(f"   2. Configure at least 1 cloud API key: /config")

def demo_response_length_limits():
    """Demonstrate response length configuration"""
    print("\nğŸ“ Response Length Limits Demo")
    print("=" * 30)
    
    try:
        assistant = KaliGPTMCPAssistant()
        
        print("ğŸ”§ Current response configuration:")
        for category, limits in assistant.response_config.items():
            print(f"\n{category.title()}:")
            for limit_type, value in limits.items():
                print(f"  â€¢ {limit_type}: {value}")
        
        print("\nğŸ’¡ Response length limits help control:")
        print("  â€¢ Maximum tokens per response type")
        print("  â€¢ Timeout duration per operation")
        print("  â€¢ Quality vs speed trade-offs")
        
    except Exception as e:
        print(f"âŒ Error demonstrating response limits: {e}")

def demo_model_communication():
    """Demonstrate model communication capabilities"""
    print("\nğŸ’¬ Model Communication Demo")
    print("=" * 30)
    
    try:
        assistant = KaliGPTMCPAssistant()
        
        print("ğŸ”§ Communication features:")
        print(f"  â€¢ Collaborative mode: {assistant.collaborative_mode}")
        print(f"  â€¢ Model communication: {assistant.model_communication_enabled}")
        print(f"  â€¢ Rephrasing mode: {assistant.rephrasing_mode}")
        
        print("\nğŸ’¡ Model communication enables:")
        print("  â€¢ Local models to deliberate together")
        print("  â€¢ Cloud models to summarize deliberations")
        print("  â€¢ Cross-model knowledge sharing")
        print("  â€¢ Consensus building")
        
    except Exception as e:
        print(f"âŒ Error demonstrating model communication: {e}")

def main():
    """Main demonstration function"""
    print("ğŸ§  Welcome to the Advanced Collaborative AI System Demo!")
    print("This showcases the revolutionary AI deliberation system where:")
    print("  â€¢ Local uncensored models discuss topics together")
    print("  â€¢ Cloud AI models summarize the deliberation")
    print("  â€¢ Cloud models only see the discussion, not the original question")
    print("  â€¢ Response length limits control output quality")
    
    time.sleep(2)
    
    # Run demonstrations
    demo_advanced_deliberation()
    demo_response_length_limits()
    demo_model_communication()
    
    print("\nğŸ‰ Advanced Collaborative AI Demo Complete!")
    print("Key features demonstrated:")
    print("  ğŸ§  Multi-model deliberation system")
    print("  ğŸ“ Cloud-based summarization")
    print("  ğŸ“ Configurable response length limits")
    print("  ğŸ’« Enhanced model communication")
    print("  ğŸ”§ Quality control mechanisms")
    
    print("\nğŸš€ Ready to use advanced collaborative AI!")

if __name__ == "__main__":
    main()
